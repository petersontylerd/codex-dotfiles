# schema_version: 2.0.0
metadata:
  product_name: ""
  based_on_artifacts:
    - "brainstorm.yaml"
    - "vision.yaml"
    - "strategy.yaml"
    - "roadmap.yaml"
  schema_version: "1.0.0"

overview:
  summary: ""                       
  goals: []                         
  non_goals: []                     
  success_metrics: []               
  assumptions: []                   
  out_of_scope: []                  

users_use_cases:
  primary_use_cases:
    - name: ""
      personas: []
      description: ""
      value_hypothesis: ""          

functional_requirements:
  - id: ""                          
    title: ""
    description: ""                 
    user_value: ""                  
    acceptance_criteria:            
      - ""                          # Gherkin preferred, freeform allowed
    priority: ""                    # Must | Should | Could | Wonâ€™t
    roadmap_time_horizon: ""        # short-term | mid-term | long-term
    dependencies: []                
    notes: ""                       

descriptive_analytics_design:
  business_rules: []                # [rule definitions and logic]
  statistical_methods: []          # [analytical approaches and formulas]
  heuristics: []                   # [decision rules and shortcuts]
  dashboard_requirements: []       # [visualization and reporting specs]
  data_sources: []                 # [source systems and datasets]
  data_quality_needs: ""           # statistical validity and bias considerations
  governance_notes: ""             # access controls and data handling
  user_value_drivers: []           # [how this solves specific user pain points]

machine_learning_design:
  model_candidates: []             # [model types and approaches]
  prediction_targets: []           # [outcomes to predict]
  training_data_requirements: []   # [datasets, volumes, labeling needs]
  feature_engineering: []          # [feature definitions and transformations]
  evaluation_framework:
    metrics: []                    # [accuracy, precision, recall, etc.]
    methods: []                    # [validation approaches]
    targets: {}                    # [threshold values]
  performance_monitoring:
    drift_detection: ""            # approach to model drift
    retraining_triggers: []        # [conditions for model updates]
  interpretability_needs: ""       # transparency and explainability requirements
  user_value_drivers: []           # [how this solves specific user pain points]

generative_ai_design:
  llm_use_cases: []                # [specific applications and scenarios]
  model_selection:
    candidates: []                 # [model options and rationale]
    hosting_approach: ""           # cloud API vs self-hosted
  retrieval_indexing:
    use_rag: false
    sources: []                    # [knowledge bases and document stores]
    chunking_policy: ""            # text segmentation strategy
    freshness_policy: ""           # update frequency and triggers
  prompting_generation:
    patterns: []                   # [prompt templates and strategies]
    prompt_specs: []               # [specific prompt requirements]
  safety_guardrails:
    pii_handling: ""               # mandatory stance on sensitive data
    jailbreak_protection: ""       # prompt injection prevention
    content_safety: ""             # harmful content filtering
    human_in_the_loop: ""          # review and approval workflows
    fallback_behavior: ""          # handling when AI fails
  cost_management:
    token_budgets: ""              # usage limits and controls
    cost_per_request_target: ""    # target cost thresholds
  user_value_drivers: []           # [how this solves specific user pain points]

ai_integration_design:
  interdependencies: []            # [how approaches work together]
  data_flow: ""                    # movement between analytical methods
  orchestration_requirements: []   # [coordination and sequencing needs]
  combined_workflows: []           # [end-to-end processes using multiple approaches]
  shared_infrastructure: []        # [common data sources, APIs, dashboards]
  performance_targets:
    end_to_end_latency_ms: 0      # total user experience latency
    system_availability: ""        # uptime requirements across approaches

interfaces_experience:
  ux_flows:
    - name: ""
      description: ""               
      references: []                
  ui_content_rules: []              
  empty_error_states: []            
  api_endpoints:
    - direction: ""                 
      method: ""                    
      path: ""                      
      auth: ""                      
      notes: ""                     

non_functional_requirements:
  performance:
    p95_latency_ms: 0
    throughput_rps: 0
  availability_reliability:
    availability: ""                
    error_budget_notes: ""
  scalability:
    approach: ""                    
  observability:
    metrics: []                     
    logs_traces: []                 
  security_privacy:
    data_handling_notes: ""
    access_controls: ""
  accessibility_localization:
    accessibility: ""               
    localization: []                

dependencies:
  internal: []                      
  external: []                      
  tech_constraints: []              

risks:
  - description: ""
    type: ""                        
    mitigation: ""
    owner: ""

rollout_plan:
  phases:
    - name: ""                      # Alpha | Beta | GA or Pilot | Limited | Full GA
      entry_criteria: []            
      exit_criteria: []             
      notes: ""
  migration_backward_compat: ""     
  rollback_strategy: ""             

acceptance_validation:
  test_plan_summary: ""             
  acceptance_matrix:
    - fr_id: ""                     
      tests:
        - id: ""                    
          description: ""
          owner: ""
  signoff_owners: []                

glossary: []

confidence_assessment:
  - section: ""           # e.g., "functional_requirements", "ai_design", "interfaces"
    confidence: ""         # high | medium | low
    rationale: ""          # why low confidence
    follow_up_action: ""   # specific next step to increase confidence

progressive_decisions:
  - decision: ""           # what was decided with incomplete info
    assumption: ""         # what we assumed
    confidence: ""         # high | medium | low
    trigger_for_revisit: "" # what would make us reconsider

open_questions:
  - question: ""
    blocking: false        # does this block forward progress?
    confidence_impact: ""  # which sections this affects
    workaround: ""         # how to proceed if unresolved
